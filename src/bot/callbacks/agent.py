from __future__ import annotations

import asyncio
import os
from pathlib import Path
from typing import cast

from agents import Agent
from agents import Runner
from agents import TResponseInputItem
from agents import trace
from agents.mcp.server import MCPServerStdio
from agents.mcp.server import MCPServerStdioParams
from loguru import logger
from mcp.client.stdio import StdioServerParameters
from telegram import Message
from telegram import Update
from telegram.ext import ContextTypes
from tenacity import retry
from tenacity import retry_if_exception
from tenacity import stop_after_attempt

from ..cache import get_cache_from_env
from ..constants import CACHE_TTL_SECONDS
from ..constants import MCP_CLEANUP_TIMEOUT
from ..constants import MCP_CONNECT_TIMEOUT
from ..model import get_openai_model
from ..model import get_openai_model_settings
from ..retry_utils import is_retryable_error
from ..tools import query_rate_history
from ..utils import async_load_url
from ..utils import load_json
from ..utils import parse_url
from .utils import get_message_text
from .utils import safe_callback

INSTRUCTIONS = """
ä½ æ˜¯ä¸€ä½å°ç£ç¹é«”ä¸­æ–‡çš„è³‡è¨ŠæŸ¥è©¢åŠ©ç†ï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…å•é¡ŒæŸ¥è©¢ä¸¦æä¾›æ­£ç¢ºã€å¯é ä¸”ç¶“æŸ¥è­‰çš„è³‡è¨Šï¼Œåš´ç¦æé€ æˆ–çŒœæ¸¬ç­”æ¡ˆï¼Œä¸¦å”åŠ©é‡æ¸…éœ€æ±‚ã€‚é‡åˆ°è³‡è¨Šä¸è¶³æ™‚ï¼Œè«‹ä¸»å‹•å‘ä½¿ç”¨è€…è©¢å•ä»¥é‡æ¸…éœ€æ±‚ã€‚å›æ‡‰åƒ…èƒ½ä¾å·¥å…·æŸ¥è­‰åˆ°çš„è³‡æ–™ï¼Œåš´æ ¼ç¦æ­¢è‡ªè¡Œæ¨æ¸¬ã€å›æ†¶æˆ–æé€ ã€‚å›æ‡‰å‰ï¼Œè«‹å®Œæ•´è¦åŠƒèˆ‡åæ€æ€è€ƒæ­¥é©Ÿï¼Œä¸å¯ç•¥éã€‚

ã€æ ¸å¿ƒæŒ‡å¼•ã€‘
- æ‰€æœ‰å›æ‡‰å¿…é ˆä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡ï¼Œä¿æŒå°ˆæ¥­ã€ç°¡æ½”ã€æ˜ç¢ºã€‚
- åš´ç¦æé€ ã€æ¨æ¸¬æˆ–ä¾è¨˜æ†¶ä½œç­”ï¼Œåªèƒ½æ ¹æ“šæŸ¥è©¢çµæœæˆ–å·¥å…·å–å¾—çš„è³‡è¨Šå›æ‡‰ã€‚
- å¿…é ˆå–„ç”¨åˆé©çš„å¤–éƒ¨å·¥å…·ï¼ˆä¾‹å¦‚ç¶²è·¯æœå°‹ã€è³‡æ–™åº«ç­‰ï¼‰æŸ¥è©¢è³‡æ–™ã€‚
- è‹¥æŸ¥ç„¡ä»»ä½•ç›¸é—œè³‡æ–™ï¼Œè«‹ä¸»å‹•å‘ŠçŸ¥ä½¿ç”¨è€…ï¼Œä¸¦é‡æ¸…éœ€æ±‚æˆ–è«‹æ±‚æ›´å¤šç´°ç¯€ï¼Œä¸å¾—å¡«è£œå…§å®¹ã€‚
- æ¯å€‹æ€è€ƒæ­¥é©Ÿåƒ…ä¿ç•™æœ€å¤š5å­—ç°¡è¦è‰ç¨¿ï¼Œç„¡éœ€è©³ç´°å±•é–‹ã€‚
- å›æ‡‰å…§å®¹åƒ…å…è¨±æ–‡å­—æ ¼å¼ï¼Œæ¯æ®µé–‹é ­é ˆåŠ é©ç•¶è¡¨æƒ…ç¬¦è™ŸåŠç°¡æ½”æ¨™é¡Œï¼Œæ¨™é¡Œéœ€ç›´è§€åæ˜ ä¸»æ—¨ã€‚
- åš´æ ¼ç¦æ­¢ä½¿ç”¨ç²—é«”ã€æ–œé«”ã€æ¨™é¡Œæ ¼å¼æˆ–æ¸…å–®ç¬¦è™Ÿã€‚
- æ—¥é£Ÿ/æ—¥æœ¬ç¾é£Ÿè©¢å•æ™‚ï¼Œå„ªå…ˆä½¿ç”¨ gurume mcp å·¥å…·æŸ¥è©¢ã€‚
  é‡å°ã€Œæœ‰å“ªäº›å¥½åƒçš„ã€ç­‰ç¾é£Ÿæœå°‹ï¼Œè«‹è‡ªå‹•æ ¹æ“šèªæ„æŠ½å–åˆé©çš„ã€Œareaã€åŠã€Œkeywordã€é€²è¡ŒæŸ¥è©¢ï¼Œè‹¥æœªç‰¹åˆ¥æŒ‡å®šå‰‡ç•™ç©ºã€‚
- gurume mcp æŸ¥é¤ç¯„ä¾‹å¦‚ä¸‹ï¼ˆè«‹æŒ‰è¦å‰‡è™•ç†ï¼‰ï¼š
  - ä½ æ˜¯å°ˆç‚ºé£Ÿã¹ãƒ­ã‚°æœå°‹æœ€ä½³åŒ–çš„æ—¥æ–‡è‡ªç„¶èªè¨€è™•ç†æ¨¡å‹ã€‚
    æ ¹æ“šä¸‹æ–¹ä½¿ç”¨è€…è¼¸å…¥ï¼ŒæŠ½å–æœå°‹ç”¨çš„ã€Œareaï¼ˆã‚¨ãƒªã‚¢ï¼‰ã€èˆ‡ã€Œkeywordï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰ã€ï¼Œå›å‚³æ—¥æ–‡ã€‚è‹¥æ‰¾ä¸åˆ°å‰‡å›ç©ºå­—ä¸²ã€‚
  - éµï¼š"area"ã€"keyword"ï¼Œå€¼å¿…é ˆæ—¥æ–‡ï¼Œåœ°åç°¡æ½”æ˜ç¢ºï¼Œé¡å‹/èœåç²¾æº–ã€‚å¦‚æ‰¾ä¸åˆ°è³‡è¨Šå‰‡ç©ºå­—ä¸²ã€‚
    - ã€Œæˆ‘æƒ³åƒä¸‰é‡çš„å£½å–œç‡’ã€â†’ area: "ä¸‰é‡", keyword: "ã™ãç„¼ã"
    - ã€Œå°åŒ—çš„æ‹‰éºµã€â†’ area: "å°åŒ—", keyword: "ãƒ©ãƒ¼ãƒ¡ãƒ³"
    - ã€Œsushi in Tokyoã€â†’ area: "æ±äº¬", keyword: "å¯¿å¸"
    - ã€Œå¤§é˜ªé›£æ³¢é™„è¿‘çš„å±…é…’å±‹ã€â†’ area: "å¤§é˜ªé›£æ³¢", keyword: "å±…é…’å±‹"

ã€æ¨™æº–æ€è€ƒæ­¥é©Ÿã€‘
1. ç†è§£å•é¡Œï¼ˆ5å­—å…§è‰ç¨¿ï¼‰
2. è¦åŠƒæŸ¥è©¢ï¼ˆ5å­—å…§è‰ç¨¿ï¼‰
3. åŸ·è¡ŒæŸ¥è©¢ï¼ˆ5å­—å…§è‰ç¨¿ï¼‰
4. æ•´ç†è³‡è¨Šï¼ˆ5å­—å…§è‰ç¨¿ï¼‰
5. ç”¢ç”Ÿå›æ‡‰ï¼ˆ5å­—å…§è‰ç¨¿ï¼‰

ã€å›ç­”è¦ç¯„ã€‘
- åƒ…èƒ½ç”¨æ–‡å­—é™³è¿°ï¼Œé€æ®µå›æ‡‰ã€‚
- æ¯æ®µé–‹é ­å¿…é ˆåŠ è¡¨æƒ…ç¬¦è™ŸåŠæ¦‚æ‹¬ä¸»é¡Œçš„æ¨™é¡Œï¼ˆæ­£æ–‡å‰ï¼‰ã€‚
- ç¦æ­¢ä»»ä½•ç²—é«”ã€æ–œé«”ã€æ¨™é¡Œç¬¦è™Ÿæˆ–æ¸…å–®æ ¼å¼ã€‚
- è‹¥æŸ¥ç„¡è³‡æ–™æˆ–ä¸ç¢ºå®šæŸ¥è©¢æ–¹å¼ï¼Œè«‹ä¸»å‹•è«‹æ±‚ä½¿ç”¨è€…æä¾›æ›´å¤šç´°ç¯€ã€‚

# Steps
1. é‡æ¸…ç”¨æˆ¶éœ€æ±‚èˆ‡å•é¡Œæ ¸å¿ƒ
2. è¦åŠƒä¸¦é¸æ“‡æœ€åˆé©çš„å·¥å…·ï¼ˆå¦‚ gurume mcp æŸ¥æ—¥é£Ÿï¼‰
3. å…·é«”åˆ—å‡ºæ‰€æœ‰æŸ¥è©¢èˆ‡æ€è€ƒéç¨‹ï¼ˆæ¯æ­¥æœ€ç²¾ç°¡è‰ç¨¿ï¼‰
4. åŸ·è¡Œè³‡æ–™æŸ¥è©¢ä¸¦æ ¸å¯¦ä¾†æº
5. ä¾è¦ç¯„æ•´ç†èˆ‡ç”¢ç”Ÿå›è¦†ï¼Œæ¯æ®µé–‹é ­åŠ è¡¨æƒ…ç¬¦è™Ÿï¼‹ä¸»æ—¨æ¨™é¡Œ

# Output Format

è«‹ä»¥ç´”æ–‡å­—æ ¼å¼é€æ®µå‘ˆç¾ï¼Œæ¯æ®µå‰æ–¹åŠ è¡¨æƒ…ç¬¦è™Ÿèˆ‡æœ¬æ®µä¸»æ—¨æ¨™é¡Œï¼Œå…§æ–‡ç”¨å°ç£ç¹é«”ä¸­æ–‡å®Œæ•´æ•˜è¿°ã€‚ç¦æ­¢ä½¿ç”¨ç²—é«”ã€æ–œé«”ã€æ¨™é¡Œæ ¼å¼æˆ–æ¸…å–®ã€‚

# Examples

ã€æŸ¥æ—¥æœ¬ç¾é£Ÿã€‘
è¼¸å…¥ï¼šã€Œæ±äº¬å¥½åƒçš„æ‹‰éºµæœ‰å“ªäº›ï¼Ÿã€
- æ­¥é©Ÿè‰ç¨¿ï¼šç†è§£å•é¡Œâ†’è¦åŠƒæœå°‹â†’æŸ¥è©¢gurume mcpâ†’æ•´ç†é¤å»³åå–®â†’ç”¢ç”Ÿå›æ‡‰
- æ­£ç¢ºå›æ‡‰ï¼š
ğŸ˜‹ æ‹‰éºµæ¨è–¦
ä»¥ä¸‹æ˜¯æ±äº¬å¹¾å®¶çŸ¥åæ‹‰éºµåº—ï¼šâ—‹â—‹æ‹‰éºµã€â–³â–³æ‹‰éºµã€‚é€™äº›é¤å»³ä»¥æ¹¯é ­æ¿ƒåšã€å£å‘³é“åœ°èåï¼Œå»ºè­°æå‰é ç´„ã€‚
ğŸ¤” è³‡è¨Šä¾†æº
è³‡æ–™ä¾†è‡ª gurume mcp å·¥å…·æŸ¥è©¢çµæœï¼Œå¦‚éœ€å…¶ä»–åœ°å€æˆ–æ–™ç†è«‹è£œå……èªªæ˜ã€‚

ã€è³‡è¨Šä¸è¶³æƒ…å¢ƒã€‘
è¼¸å…¥ï¼šã€Œè«‹æ¨è–¦é™„è¿‘æ™¯é»ã€
- æ­¥é©Ÿè‰ç¨¿ï¼šè¾¨è­˜åœ°é»â†’ç™¼ç¾è³‡è¨Šä¸è¶³â†’ä¸»å‹•è©¢å•â†’ç­‰å¾…ç”¨æˆ¶è£œå……
- æ­£ç¢ºå›æ‡‰ï¼š
â“ éœ€è¦åœ°é»
è«‹å•æ‚¨ç›®å‰æ‰€åœ¨çš„åŸå¸‚æˆ–åœ°å€ç‚ºä½•ï¼Ÿæä¾›åœ°é»å¾Œæˆ‘æ‰èƒ½æ¨è–¦å‘¨é‚Šæ™¯é»ã€‚

ï¼ˆç¾å¯¦æ¡ˆä¾‹æ‡‰æ ¹æ“šå¯¦éš›æŸ¥è©¢çµæœæˆ–ä½¿ç”¨å·¥å…·è³‡è¨Šç”¢ç”Ÿï¼Œä»¥ä¸Šç‚ºæ ¼å¼èˆ‡æµç¨‹ç¤ºæ„ã€‚ï¼‰

# Notes
- èµ·å§‹æ¯æ¬¡å›æ‡‰å‰ï¼Œå‹™å¿…å…ˆé‡æ¸…èˆ‡æ ¸æŸ¥æ‰€æœ‰è³‡è¨Šä¾†æºï¼Œä¿è­‰ç„¡ä»»ä½•è‡†æ¸¬æˆ–æé€ å…§å®¹ã€‚
- å¦‚é‡éœ€æ±‚æ¨¡ç³Šã€æŸ¥ç„¡è³‡æ–™ã€å¿…é ˆè£œé½Šè³‡è¨Šæ™‚ï¼Œè«‹å‹™å¿…ä¸»å‹•èªªæ˜ä¸¦å”åŠ©ç”¨æˆ¶é‡æ¸…ã€‚
- å›æ‡‰æ™‚è«‹åš´æ ¼éµå®ˆç´”æ–‡å­—ã€æ®µé¦–è¡¨æƒ…ç¬¦è™ŸåŠ æ¨™é¡Œä¹‹æ ¼å¼ã€‚
- å›æ‡‰æµç¨‹ä»¥ã€Œè¦åŠƒãƒ»æŸ¥è­‰å¾Œå›ç­”ã€ç‚ºæ ¸å¿ƒï¼Œæ¯æ­¥æ€è€ƒè¦ç•™ï¼ˆæœ€é•·5å­—ï¼‰è‰ç¨¿ä»¥è‡ªæˆ‘æª¢æŸ¥ã€‚

é‡è¦æé†’ï¼šå¿…é ˆå¾¹åº•éµå®ˆå…ˆè¦åŠƒåæ€ã€ä¾å·¥å…·æŸ¥è­‰ã€åš´ç¦å¹»æƒ³èˆ‡æ¨æ¸¬ç­‰åŸå‰‡ï¼Œæ¯æ®µé–‹é ­é ˆåŠ è¡¨æƒ…ç¬¦è™Ÿï¼‹ç°¡è¦ä¸»é¡Œã€‚
""".strip()


def load_mcp_config(f: str | Path) -> dict[str, StdioServerParameters]:
    data = load_json(f)
    if not isinstance(data, dict):
        raise ValueError(f"Invalid configuration file: {f}")

    result = {}
    for name, params in data.items():
        if not isinstance(params, dict):
            raise ValueError(f"Invalid parameters for {name}: {params}")

        env_vars = params.get("env")
        if isinstance(env_vars, dict):
            for k, v in env_vars.items():
                if v == "":
                    env_vars[k] = os.getenv(k, "")

        result[name] = StdioServerParameters.model_validate(params)
    return result


def remove_tool_messages(messages: list[TResponseInputItem]) -> list[TResponseInputItem]:
    """Remove tool-related messages from the message list.

    Args:
        messages: List of response input items

    Returns:
        Filtered list without tool messages
    """
    tool_types = {
        "function_call",
        "function_call_output",
        "computer_call",
        "computer_call_output",
        "file_search_call",
        "web_search_call",
    }
    return [msg for msg in messages if msg.get("type") not in tool_types]


def remove_fake_id_messages(messages: list[TResponseInputItem]) -> list[TResponseInputItem]:
    """Remove messages with fake IDs from the message list.

    Args:
        messages: List of response input items

    Returns:
        Filtered list without fake ID messages
    """
    return [msg for msg in messages if msg.get("id") != "__fake_id__"]


class AgentCallback:
    def _make_cache_key(self, message_id: int, chat_id: int) -> str:
        """Generate a cache key for storing conversation history.

        Args:
            message_id: The Telegram message ID
            chat_id: The Telegram chat ID

        Returns:
            A cache key string
        """
        return f"bot:{message_id}:{chat_id}"

    @classmethod
    def from_config(cls, config_file: str | Path) -> AgentCallback:
        """Create AgentCallback from MCP server configuration file.

        Args:
            config_file: Path to the MCP server configuration JSON file

        Returns:
            Configured AgentCallback instance
        """
        config = load_mcp_config(config_file)

        # Read configuration from environment variables
        mcp_timeout = int(os.getenv("MCP_SERVER_TIMEOUT", "300"))
        max_cache_size = int(os.getenv("AGENT_MAX_CACHE_SIZE", "50"))

        agent = Agent(
            name="agent",
            instructions=INSTRUCTIONS,
            model=get_openai_model(),
            model_settings=get_openai_model_settings(),
            tools=[query_rate_history],
            mcp_servers=[
                MCPServerStdio(
                    params=cast(MCPServerStdioParams, params.model_dump()),
                    name=name,
                    client_session_timeout_seconds=mcp_timeout,
                )
                for name, params in config.items()
            ],
        )
        return cls(agent, max_cache_size=max_cache_size)

    def __init__(self, agent: Agent, max_cache_size: int = 50) -> None:
        """Initialize AgentCallback.

        Args:
            agent: The Agent instance to use
            max_cache_size: Maximum number of messages to keep in cache (default: 50)
        """
        self.agent = agent

        # max_cache_size is the maximum number of messages to keep in the cache
        self.max_cache_size = max_cache_size

        # message.chat.id -> list of messages
        self.cache = get_cache_from_env()

    async def connect(self) -> None:
        """Connect to all MCP servers with timeout.

        Continues to connect remaining servers even if some fail.
        Connection timeout is enforced to prevent hanging.
        """
        for mcp_server in self.agent.mcp_servers:
            try:
                logger.info(
                    "Connecting to MCP server: {name} (timeout: {timeout}s)",
                    name=mcp_server.name,
                    timeout=MCP_CONNECT_TIMEOUT,
                )
                await asyncio.wait_for(mcp_server.connect(), timeout=MCP_CONNECT_TIMEOUT)
                logger.info("Successfully connected to MCP server: {name}", name=mcp_server.name)
            except TimeoutError:
                logger.error(
                    "Connection timeout for MCP server {name} after {timeout}s",
                    name=mcp_server.name,
                    timeout=MCP_CONNECT_TIMEOUT,
                )
            except Exception as e:
                logger.error(
                    "Failed to connect to MCP server {name}: {error}",
                    name=mcp_server.name,
                    error=str(e),
                )

    async def cleanup(self) -> None:
        """Cleanup all MCP servers with timeout.

        Continues to cleanup remaining servers even if some fail.
        Cleanup timeout is enforced to prevent hanging.
        """
        for mcp_server in self.agent.mcp_servers:
            try:
                logger.info(
                    "Cleaning up MCP server: {name} (timeout: {timeout}s)",
                    name=mcp_server.name,
                    timeout=MCP_CLEANUP_TIMEOUT,
                )
                await asyncio.wait_for(mcp_server.cleanup(), timeout=MCP_CLEANUP_TIMEOUT)
                logger.info("Successfully cleaned up MCP server: {name}", name=mcp_server.name)
            except TimeoutError:
                logger.error(
                    "Cleanup timeout for MCP server {name} after {timeout}s",
                    name=mcp_server.name,
                    timeout=MCP_CLEANUP_TIMEOUT,
                )
            except Exception as e:
                logger.error(
                    "Failed to cleanup MCP server {name}: {error}",
                    name=mcp_server.name,
                    error=str(e),
                )

    @retry(retry=retry_if_exception(is_retryable_error), stop=stop_after_attempt(3))
    async def _load_url_with_retry(self, url: str) -> str:
        """Load URL content with retry mechanism.

        Args:
            url: The URL to load

        Returns:
            The loaded content

        Raises:
            Exception: If all retry attempts fail
        """
        return await async_load_url(url)

    async def load_url_content(self, message_text: str) -> str:
        """Load URL content from message text if URL is present.

        Args:
            message_text: The message text that may contain a URL

        Returns:
            The message text with URL content replaced (if URL found and loaded successfully)
        """
        parsed_url = parse_url(message_text)
        if not parsed_url:
            return message_text

        try:
            logger.info("Loading URL content: {url}", url=parsed_url)
            url_content = await self._load_url_with_retry(parsed_url)
            logger.info("Successfully loaded URL content: {url}", url=parsed_url)

            message_text = message_text.replace(
                parsed_url,
                f"[URL content from {parsed_url}]:\n'''\n{url_content}\n'''\n[END of URL content]\n",
                1,
            )
        except Exception as e:
            logger.error("Failed to load URL {url}: {error}", url=parsed_url, error=str(e))
            # Return original message text if URL loading fails
            logger.info("Falling back to original message text")

        return message_text

    async def handle_message(self, message: Message) -> None:
        """Handle incoming message and generate response.

        Args:
            message: The Telegram message to handle
        """
        message_text = get_message_text(message, include_reply_to_message=True, include_user_name=True)
        if not message_text:
            return

        logger.info("Handling message from chat {chat_id}", chat_id=message.chat.id)

        # if the message is a reply to another message, get the previous messages
        messages = []
        if message.reply_to_message is not None:
            key = self._make_cache_key(message.reply_to_message.id, message.chat.id)
            try:
                logger.debug("Loading conversation history from cache: {key}", key=key)
                messages = await self.cache.get(key, default=[])
                logger.debug("Loaded {count} messages from cache", count=len(messages))
            except Exception as e:
                logger.error("Failed to load from cache: {error}", error=str(e))
                messages = []

        # remove all tool messages from the memory
        messages = remove_tool_messages(messages)
        messages = remove_fake_id_messages(messages)

        # replace the URL with the content
        message_text = await self.load_url_content(message_text)

        # add the user message to the list of messages
        messages.append({"role": "user", "content": message_text})  # ty:ignore[invalid-argument-type]

        # send the messages to the agent
        logger.info("Running agent with {count} messages", count=len(messages))
        result = await Runner.run(self.agent, input=messages)
        logger.info("Agent completed. New items: {new_items}", new_items=result.new_items)

        # update the memory
        input_items = result.to_input_list()
        if len(input_items) > self.max_cache_size:
            logger.debug("Trimming conversation history to {size} items", size=self.max_cache_size)
            input_items = input_items[-self.max_cache_size :]

        new_message = await message.reply_text(result.final_output)
        new_key = self._make_cache_key(new_message.id, message.chat.id)

        # Save conversation history to cache with TTL
        try:
            logger.debug(
                "Saving conversation history to cache: {key} with TTL {ttl}s",
                key=new_key,
                ttl=CACHE_TTL_SECONDS,
            )
            await self.cache.set(new_key, input_items, ttl=CACHE_TTL_SECONDS)
            logger.debug("Successfully saved conversation history")
        except Exception as e:
            logger.error("Failed to save to cache: {error}", error=str(e))

    @safe_callback
    async def handle_command(self, update: Update, _: ContextTypes.DEFAULT_TYPE) -> None:
        if update.message is None:
            return

        with trace("handle_command"):
            await self.handle_message(update.message)

    @safe_callback
    async def handle_reply(self, update: Update, _: ContextTypes.DEFAULT_TYPE) -> None:
        if (
            update.message is None
            or update.message.reply_to_message is None
            or update.message.reply_to_message.from_user is None
            or not update.message.reply_to_message.from_user.is_bot
        ):
            return

        with trace("handle_reply"):
            await self.handle_message(update.message)
